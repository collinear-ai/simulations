{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Load the standard library helpers and the Collinear client used below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "from collinear.client import Client\n",
    "\n",
    "# Necessary to run in a Jupyter notebook\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "Read the simulation settings and TraitMix configuration from the `configs/` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = Path('configs')\n",
    "SIMULATION_CONFIG_FILE = CONFIG_DIR / 'simulation_config.json'\n",
    "config_data = json.loads(SIMULATION_CONFIG_FILE.read_text())\n",
    "\n",
    "traitmix_config_value = config_data.get('traitmix_config_file') or 'traitmix_config_airline.json'\n",
    "traitmix_candidate = Path(traitmix_config_value)\n",
    "if not traitmix_candidate.is_absolute():\n",
    "    traitmix_candidate = CONFIG_DIR / traitmix_candidate.name\n",
    "TRAITMIX_CONFIG_FILE = traitmix_candidate\n",
    "TRAITMIX_CONFIG = json.loads(TRAITMIX_CONFIG_FILE.read_text())\n",
    "TRAITMIX_TASKS = list(TRAITMIX_CONFIG.get('tasks', []))\n",
    "\n",
    "client_settings = config_data.get('client', {}) or {}\n",
    "CLIENT_ASSISTANT_MODEL_URL = client_settings.get('assistant_model_url', 'https://api.openai.com/v1')\n",
    "CLIENT_ASSISTANT_MODEL_API_KEY = client_settings.get('assistant_model_api_key')\n",
    "CLIENT_ASSISTANT_MODEL_NAME = client_settings.get('assistant_model_name', 'gpt-4o-mini')\n",
    "CLIENT_COLLINEAR_API_KEY = client_settings.get('collinear_api_key', 'demo-001')\n",
    "CLIENT_TIMEOUT = float(client_settings.get('timeout', 120))\n",
    "CLIENT_MAX_RETRIES = int(client_settings.get('max_retries', 3))\n",
    "CLIENT_RATE_LIMIT_RETRIES = int(client_settings.get('rate_limit_retries', 6))\n",
    "\n",
    "simulate_settings = config_data.get('simulate', {}) or {}\n",
    "SIM_SAMPLES = simulate_settings.get('k', 1)\n",
    "SIM_EXCHANGES = simulate_settings.get('num_exchanges', 2)\n",
    "SIM_DELAY = simulate_settings.get('batch_delay', 0.2)\n",
    "SIM_TRAITMIX_TEMPERATURE = simulate_settings.get('traitmix_temperature', 0.7)\n",
    "SIM_TRAITMIX_MAX_TOKENS = simulate_settings.get('traitmix_max_tokens', 256)\n",
    "SIM_MIX_TRAITS = bool(simulate_settings.get('mix_traits', False))\n",
    "SIM_MAX_CONCURRENCY = int(simulate_settings.get('max_concurrency', 8))\n",
    "\n",
    "assess_settings = config_data.get('assess', {}) or {}\n",
    "ASSESS_JUDGE_MODEL_URL = assess_settings.get('judge_model_url')\n",
    "ASSESS_JUDGE_MODEL_API_KEY = assess_settings.get('judge_model_api_key')\n",
    "ASSESS_JUDGE_MODEL_NAME = assess_settings.get('judge_model_name')\n",
    "ASSESS_TEMPERATURE = assess_settings.get('temperature', 0.0)\n",
    "ASSESS_MAX_TOKENS = assess_settings.get('max_tokens', 512)\n",
    "\n",
    "print(f'Loaded simulation: {SIMULATION_CONFIG_FILE} | traitmix: {TRAITMIX_CONFIG_FILE} | tasks: {TRAITMIX_TASKS or \"<none>\"}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Client\n",
    "\n",
    "Create the Collinear client using the loaded credentials and runtime options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1757534412670,
     "user": {
      "displayName": "Quinten Lisowe",
      "userId": "05399425339750097468"
     },
     "user_tz": 300
    },
    "id": "p33x-dw2Lqx5"
   },
   "outputs": [],
   "source": [
    "if not CLIENT_ASSISTANT_MODEL_API_KEY:\n",
    "    raise RuntimeError('assistant_model_api_key must be set in configs/simulation_config.json')\n",
    "\n",
    "client = Client(\n",
    "    assistant_model_url=CLIENT_ASSISTANT_MODEL_URL,\n",
    "    assistant_model_api_key=CLIENT_ASSISTANT_MODEL_API_KEY,\n",
    "    assistant_model_name=CLIENT_ASSISTANT_MODEL_NAME,\n",
    "    collinear_api_key=CLIENT_COLLINEAR_API_KEY,\n",
    "    timeout=CLIENT_TIMEOUT,\n",
    "    max_retries=CLIENT_MAX_RETRIES,\n",
    "    rate_limit_retries=CLIENT_RATE_LIMIT_RETRIES,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulations\n",
    "\n",
    "Generate synthetic conversations for the selected TraitMix configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36427,
     "status": "ok",
     "timestamp": 1757534450373,
     "user": {
      "displayName": "Quinten Lisowe",
      "userId": "05399425339750097468"
     },
     "user_tz": 300
    },
    "id": "Jy4gD4iMLuh6",
    "outputId": "aa427389-2aab-454f-bcde-93d8a83e7f53"
   },
   "outputs": [],
   "source": [
    "simulations = client.simulate(\n",
    "    traitmix_config=TRAITMIX_CONFIG,\n",
    "    k=SIM_SAMPLES,\n",
    "    num_exchanges=SIM_EXCHANGES,\n",
    "    batch_delay=SIM_DELAY,\n",
    "    traitmix_temperature=SIM_TRAITMIX_TEMPERATURE,\n",
    "    traitmix_max_tokens=SIM_TRAITMIX_MAX_TOKENS,\n",
    "    mix_traits=SIM_MIX_TRAITS,\n",
    "    max_concurrency=SIM_MAX_CONCURRENCY,\n",
    ")\n",
    "\n",
    "for i, sim in enumerate(simulations, start=1):\n",
    "    p = getattr(sim, 'traitmix', None)\n",
    "    if p is not None:\n",
    "        print(\n",
    "            \"TraitMix Persona:\\n\"\n",
    "            f\"age={p.age}\\n\"\n",
    "            f\"gender={p.gender}\\n\"\n",
    "            f\"occupation={p.occupation}\\n\"\n",
    "            f\"intent={p.intent}\\n\"\n",
    "            f\"trait={p.trait}\" if p.trait else f\"traits={p.traits}\"\n",
    "        )\n",
    "    print(\"---\")\n",
    "    for msg in sim.conv_prefix:\n",
    "        role = str(msg.get('role', ''))\n",
    "        content = str(msg.get('content', ''))\n",
    "        if content:\n",
    "            print(f\"{role}: {content}\")\n",
    "    print(f\"assistant: {sim.response}\")\n",
    "    print()\n",
    "print('All simulations complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Conversations\n",
    "\n",
    "Score the generated conversations with the local assessment helper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5102,
     "status": "ok",
     "timestamp": 1757534622310,
     "user": {
      "displayName": "Quinten Lisowe",
      "userId": "05399425339750097468"
     },
     "user_tz": 300
    },
    "id": "50fa3grpLxa_",
    "outputId": "123eb24e-78ac-48a4-81af-23b94e9d4a85"
   },
   "outputs": [],
   "source": [
    "result = client.assess(\n",
    "    dataset=simulations,\n",
    "    judge_model_url=ASSESS_JUDGE_MODEL_URL,\n",
    "    judge_model_api_key=ASSESS_JUDGE_MODEL_API_KEY,\n",
    "    judge_model_name=ASSESS_JUDGE_MODEL_NAME,\n",
    "    temperature=ASSESS_TEMPERATURE,\n",
    "    max_tokens=ASSESS_MAX_TOKENS,\n",
    ")\n",
    "print(f\"Assessment: {result.message or '<no message>'}\")\n",
    "for scores_map in result.evaluation_result:\n",
    "    for scores in scores_map.values():\n",
    "        print(f\"  Score: {scores.score}\")\n",
    "        print(f\"  Rationale: {scores.rationale}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM7rchU09Jpkc2yxReTbFAy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "collinear-synthetic",
   "language": "python",
   "name": "collinear-synthetic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
