{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686e8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bfcl_trait_eval._llm_response_generation import main as generation_main\n",
    "from bfcl_trait_eval.eval_checker.eval_runner import main as evaluation_main\n",
    "from types import SimpleNamespace\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e26874",
   "metadata": {},
   "source": [
    "### BFCL Trait Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa9c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BFCL_CONFIG_PATH = \"config/bfcl_config.json\"\n",
    "\n",
    "config = json.load(open(BFCL_CONFIG_PATH, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d3d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: str = config.get(\"model\", \"moonshotai/Kimi-K2-Instruct-0905\")\n",
    "model_type: str = config.get(\"model_type\", \"together\")\n",
    "api_key: str = config.get(\"api_key\", os.environ.get(\"TOGETHER_API_KEY\", \"\"))\n",
    "is_fc_model: bool = config.get(\"is_fc_model\", False)\n",
    "test_category: str = config.get(\"test_category\", \"multi_turn_base\")\n",
    "temperature: float = config.get(\"temperature\", 0.001)\n",
    "include_input_log: bool = config.get(\"include_input_log\", False)\n",
    "exclude_state_log: bool = config.get(\"exclude_state_log\", False)\n",
    "num_threads: int = config.get(\"num_threads\", 1)\n",
    "skip_server_setup: bool = config.get(\"skip_server_setup\", False)\n",
    "local_model_path: str = config.get(\"local_model_path\", None)\n",
    "result_dir: str = config.get(\"result_dir\", \"result\")\n",
    "score_dir: str = config.get(\"score_dir\", \"score\")\n",
    "allow_overwrite: bool = config.get(\"allow_overwrite\", False)\n",
    "run_ids: bool = config.get(\"run_ids\", False)\n",
    "trait: str = config.get(\"trait\", \"skeptical\") # possible options: \"skeptical\", \"confusion\", \"impatience\", \"incoherence\"\n",
    "intensity: str = config.get(\"intensity\", \"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359e3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    model=model,\n",
    "    model_type=model_type,\n",
    "    is_fc_model=is_fc_model,\n",
    "    api_key=api_key,\n",
    "    test_category=test_category,\n",
    "    temperature=temperature,\n",
    "    include_input_log=include_input_log,\n",
    "    exclude_state_log=exclude_state_log,\n",
    "    num_threads=num_threads,\n",
    "    result_dir=result_dir,\n",
    "    allow_overwrite=allow_overwrite,\n",
    "    run_ids=run_ids,\n",
    "    trait=trait,\n",
    "    intensity=intensity,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1c957",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d52b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5195f153",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af66b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of models evaluated: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦ Model: moonshotai_Kimi-K2-Instruct-0905\n",
      "ðŸ” Running test: multi_turn_base\n",
      "âœ… Test completed: multi_turn_base. ðŸŽ¯ Accuracy: 0.00%\n",
      "ðŸ Evaluation completed. See /root/bfcl_trait/score/data_overall.csv for overall evaluation results on BFCL V4.\n",
      "âš ï¸  Partial evaluation for a single category is enabled (--partial-run flag is set). Accuracy scores are computed only on the subset of entries present in the model result files, which may differ from a full evaluation and from the official leaderboard score.\n",
      "See /root/bfcl_trait/score/data_live.csv, /root/bfcl_trait/score/data_non_live.csv, /root/bfcl_trait/score/data_multi_turn.csv, /root/bfcl_trait/score/data_agentic.csv and /root/bfcl_trait/score/data_format_sensitivity.csv for detailed evaluation results on each sub-section categories respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_main([model], test_category, result_dir, score_dir, trait, intensity, partial_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8bb64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
