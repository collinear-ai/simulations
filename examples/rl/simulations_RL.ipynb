{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-aat5zD6-on"
   },
   "source": [
    "## Install packages and set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11998,
     "status": "ok",
     "timestamp": 1757470582420,
     "user": {
      "displayName": "Quinten Lisowe",
      "userId": "05399425339750097468"
     },
     "user_tz": 300
    },
    "id": "IXh_KBjM62NV",
    "outputId": "b2d9e51d-c531-4f85-b45c-452055dbe4ac"
   },
   "outputs": [],
   "source": [
    "!pip install collinear --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XTQTO9b7Mej"
   },
   "source": [
    "## Load model, setup client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfrQeD_f75Gx"
   },
   "outputs": [],
   "source": [
    "# Config Variables (from configs/simulation_config.json and steering_config_*.json)\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "CONFIG_DIR = Path('configs')\n",
    "SIMULATION_CONFIG_FILE = CONFIG_DIR / 'simulation_config.json'\n",
    "config_data = json.loads(SIMULATION_CONFIG_FILE.read_text())\n",
    "\n",
    "steering_config_value = config_data.get('steering_config_file') or 'steering_config_airline.json'\n",
    "steering_candidate = Path(steering_config_value)\n",
    "if not steering_candidate.is_absolute():\n",
    "    steering_candidate = CONFIG_DIR / steering_candidate.name\n",
    "STEERING_CONFIG_FILE = steering_candidate\n",
    "STEER_CONFIG = json.loads(STEERING_CONFIG_FILE.read_text())\n",
    "STEER_TASKS = list(STEER_CONFIG.get('tasks', []))\n",
    "\n",
    "# Client options\n",
    "client_settings = config_data.get('client', {}) or {}\n",
    "CLIENT_ASSISTANT_MODEL_URL = client_settings.get('assistant_model_url', 'https://api.openai.com/v1')\n",
    "CLIENT_ASSISTANT_MODEL_API_KEY = client_settings.get('assistant_model_api_key')\n",
    "CLIENT_ASSISTANT_MODEL_NAME = client_settings.get('assistant_model_name', 'gpt-4o-mini')\n",
    "CLIENT_STEER_API_KEY = client_settings.get('steer_api_key', 'demo-001')\n",
    "CLIENT_TIMEOUT = float(client_settings.get('timeout', 120))\n",
    "CLIENT_MAX_RETRIES = int(client_settings.get('max_retries', 3))\n",
    "CLIENT_RATE_LIMIT_RETRIES = int(client_settings.get('rate_limit_retries', 6))\n",
    "\n",
    "# Simulation options\n",
    "simulate_settings = config_data.get('simulate', {}) or {}\n",
    "SIM_SAMPLES = simulate_settings.get('k', 1)\n",
    "SIM_EXCHANGES = simulate_settings.get('num_exchanges', 2)\n",
    "SIM_DELAY = simulate_settings.get('batch_delay', 0.2)\n",
    "SIM_STEER_TEMPERATURE = simulate_settings.get('steer_temperature', 0.7)\n",
    "SIM_STEER_MAX_TOKENS = simulate_settings.get('steer_max_tokens', 256)\n",
    "SIM_MIX_TRAITS = bool(simulate_settings.get('mix_traits', False))\n",
    "\n",
    "# Assessment options\n",
    "assess_settings = config_data.get('assess', {}) or {}\n",
    "ASSESS_JUDGE_MODEL_URL = assess_settings.get('judge_model_url')\n",
    "ASSESS_JUDGE_MODEL_API_KEY = assess_settings.get('judge_model_api_key')\n",
    "ASSESS_JUDGE_MODEL_NAME = assess_settings.get('judge_model_name')\n",
    "ASSESS_TEMPERATURE = assess_settings.get('temperature', 0.0)\n",
    "ASSESS_MAX_TOKENS = assess_settings.get('max_tokens', 512)\n",
    "\n",
    "\n",
    "print(f'Loaded simulation: {SIMULATION_CONFIG_FILE} | steering: {STEERING_CONFIG_FILE} | tasks: {STEER_TASKS or \"<none>\"}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36V2vEkc7WbE"
   },
   "source": [
    "## Client setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_SHN7Qq74o1"
   },
   "outputs": [],
   "source": [
    "# Client setup\n",
    "from collinear.client import Client\n",
    "\n",
    "if not CLIENT_ASSISTANT_MODEL_API_KEY:\n",
    "    raise RuntimeError('assistant_model_api_key must be set in configs/simulation_config.json')\n",
    "\n",
    "client = Client(\n",
    "    assistant_model_url=CLIENT_ASSISTANT_MODEL_URL,\n",
    "    assistant_model_api_key=CLIENT_ASSISTANT_MODEL_API_KEY,\n",
    "    assistant_model_name=CLIENT_ASSISTANT_MODEL_NAME,\n",
    "    steer_api_key=CLIENT_STEER_API_KEY,\n",
    "    timeout=CLIENT_TIMEOUT,\n",
    "    max_retries=CLIENT_MAX_RETRIES,\n",
    "    rate_limit_retries=CLIENT_RATE_LIMIT_RETRIES,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKQEJx5_7pqi"
   },
   "source": [
    "## Simulate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16496,
     "status": "ok",
     "timestamp": 1757473448091,
     "user": {
      "displayName": "Quinten Lisowe",
      "userId": "05399425339750097468"
     },
     "user_tz": 300
    },
    "id": "R8AoPk5574Bb",
    "outputId": "521b92f7-95f1-4b25-cc31-ac1d26d2f314"
   },
   "outputs": [],
   "source": [
    "# Run simulations\n",
    "simulations = client.simulate(\n",
    "    steer_config=STEER_CONFIG,\n",
    "    k=SIM_SAMPLES,\n",
    "    num_exchanges=SIM_EXCHANGES,\n",
    "    batch_delay=SIM_DELAY,\n",
    "    steer_temperature=SIM_STEER_TEMPERATURE,\n",
    "    steer_max_tokens=SIM_STEER_MAX_TOKENS,\n",
    "    mix_traits=SIM_MIX_TRAITS,\n",
    ")\n",
    "\n",
    "# Pretty-print the simulated conversations and steer details.\n",
    "for i, sim in enumerate(simulations, start=1):\n",
    "    p = sim.steer\n",
    "    if p is not None:\n",
    "        print(\n",
    "            \"Steer Persona:\\n\"\n",
    "            f\"age={p.age}\\n\"\n",
    "            f\"gender={p.gender}\\n\"\n",
    "            f\"occupation={p.occupation}\\n\"\n",
    "            f\"intent={p.intent}\\n\"\n",
    "            f\"trait={p.trait}\" if p.trait else f\"traits={p.traits}\"\n",
    "        )\n",
    "    print(\"---\")\n",
    "    for msg in sim.conv_prefix:\n",
    "        role = str(msg.get('role', ''))\n",
    "        content = str(msg.get('content', ''))\n",
    "        if content:\n",
    "            print(f\"{role}: {content}\")\n",
    "    print(f\"assistant: {sim.response}\")\n",
    "    print()\n",
    "print('All simulations complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQfuz3uR7wg5"
   },
   "source": [
    "## Assess agent in multi-turn setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4463,
     "status": "ok",
     "timestamp": 1757473545636,
     "user": {
      "displayName": "Quinten Lisowe",
      "userId": "05399425339750097468"
     },
     "user_tz": 300
    },
    "id": "xGIbbY-U72pX",
    "outputId": "e09fb84d-60cd-432d-b12b-2bfbd77d9089"
   },
   "outputs": [],
   "source": [
    "# Assess\n",
    "result = client.assess(\n",
    "    dataset=simulations,\n",
    "    judge_model_url=ASSESS_JUDGE_MODEL_URL,\n",
    "    judge_model_api_key=ASSESS_JUDGE_MODEL_API_KEY,\n",
    "    judge_model_name=ASSESS_JUDGE_MODEL_NAME,\n",
    "    temperature=ASSESS_TEMPERATURE,\n",
    "    max_tokens=ASSESS_MAX_TOKENS,\n",
    ")\n",
    "print(f\"Assessment: {result.message or '<no message>'}\")\n",
    "for scores_map in result.evaluation_result:\n",
    "    for scores in scores_map.values():\n",
    "        print(f\"  Score: {scores.score}\")\n",
    "        print(f\"  Rationale: {scores.rationale}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMI7Zd6-73Cx"
   },
   "source": [
    "## (optinal) configure and push to prime intellect hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9X-eUX5KwpP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt6gQPoD8CyS"
   },
   "source": [
    "## load tau-hard bench from prime intellect hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2755,
     "status": "ok",
     "timestamp": 1757617605913,
     "user": {
      "displayName": "Tsach Mackey",
      "userId": "06343373149479742516"
     },
     "user_tz": 420
    },
    "id": "nuz9Z1fgK_x3",
    "outputId": "286506f5-be96-48cd-fc66-58838698faf6"
   },
   "outputs": [],
   "source": [
    "!curl -LsSf https://astral.sh/uv/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1757617621231,
     "user": {
      "displayName": "Tsach Mackey",
      "userId": "06343373149479742516"
     },
     "user_tz": 420
    },
    "id": "qT1VxKS-LDMO",
    "outputId": "c0587f11-717e-4c3f-97b6-bceca577482d"
   },
   "outputs": [],
   "source": [
    "!uv tool install prime\n",
    "!uvx prime env install tsach/tau-hard@0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "error",
     "timestamp": 1757621314664,
     "user": {
      "displayName": "Tsach Mackey",
      "userId": "06343373149479742516"
     },
     "user_tz": 420
    },
    "id": "T53DNvOVLAyd",
    "outputId": "44a32bc2-fc9d-461f-9c69-2484bea4d8c3"
   },
   "outputs": [],
   "source": [
    "from verifiers import load_environment\n",
    "env = load_environment('tau-hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "error",
     "timestamp": 1757618797839,
     "user": {
      "displayName": "Tsach Mackey",
      "userId": "06343373149479742516"
     },
     "user_tz": 420
    },
    "id": "5mK4jGZnPIRn",
    "outputId": "dfc2186e-444b-48ed-8942-e01d726920c9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elRGbZCe8kQU"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epioPWSD81ud"
   },
   "source": [
    "## analyze and summarize results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}