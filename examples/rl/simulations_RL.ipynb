{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-aat5zD6-on"
   },
   "source": [
    "## Install packages and set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "from collinear.client import Client\n",
    "\n",
    "# Necessary to run in a Jupyter notebook\n",
    "nest_asyncio.apply()\n",
    "import argparse\n",
    "from tau_bench.types import RunConfig\n",
    "from tau_bench.run import run\n",
    "from litellm import provider_list\n",
    "from tau_bench.envs.user import UserStrategy\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header(title: str) -> None:\n",
    "    line = \"=\" * len(title)\n",
    "    print(line)\n",
    "    print(title)\n",
    "    print(line)\n",
    "\n",
    "def display_persona(sim_runner, simulation):\n",
    "    raw = build_steering_persona(sim_runner, getattr(simulation, 'steer', None))\n",
    "    persona = {\n",
    "      'characteristics': dict(raw.get('characteristics', {})),\n",
    "      'traits': dict(raw.get('traits', {})),\n",
    "    }\n",
    "    pprint(persona)\n",
    "\n",
    "def make_dataset_row(simulation_runner, simulation):\n",
    "    \"\"\"Build a single dataset row with persona characteristics included.\"\"\"\n",
    "    return {\n",
    "        'conversation': format_conversation(simulation.conv_prefix),\n",
    "        'assistant_response': simulation.response,\n",
    "        'steering_persona': build_steering_persona(simulation_runner, getattr(simulation, 'steer', None)),\n",
    "    }\n",
    "\n",
    "def format_conversation(conversation_prefix):\n",
    "    \"\"\"Compact conversation text from message dicts.\"\"\"\n",
    "    return '\\n'.join(\n",
    "        f\"{message.get('role', '')}: {message.get('content', '')}\"\n",
    "        for message in conversation_prefix\n",
    "        if message.get('content')\n",
    "    )\n",
    "\n",
    "def build_steering_persona(simulation_runner, steer_combination):\n",
    "    \"\"\"Return persona metadata via the runner's normalization helpers.\"\"\"\n",
    "    if steer_combination is None:\n",
    "        return {'characteristics': {}, 'traits': {}}\n",
    "    characteristics: dict[str, object] = {}\n",
    "    try:\n",
    "        characteristics = simulation_runner._user_characteristics_payload(steer_combination)\n",
    "    except Exception:\n",
    "        characteristics = {}\n",
    "    traits = getattr(steer_combination, 'traits', {}) or {}\n",
    "    return {'characteristics': characteristics, 'traits': traits}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XTQTO9b7Mej"
   },
   "source": [
    "## Load model, setup client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfrQeD_f75Gx"
   },
   "outputs": [],
   "source": [
    "# Config Variables (from configs/simulation_config.json and steering_config_*.json)\n",
    "\n",
    "CONFIG_DIR = Path('configs')\n",
    "SIMULATION_CONFIG_FILE = CONFIG_DIR / 'simulation_config.json'\n",
    "config_data = json.loads(SIMULATION_CONFIG_FILE.read_text())\n",
    "\n",
    "steering_config_value = config_data.get('steering_config_file') or 'steering_config_airline.json'\n",
    "steering_candidate = Path(steering_config_value)\n",
    "if not steering_candidate.is_absolute():\n",
    "    steering_candidate = CONFIG_DIR / steering_candidate.name\n",
    "STEERING_CONFIG_FILE = steering_candidate\n",
    "STEER_CONFIG = json.loads(STEERING_CONFIG_FILE.read_text())\n",
    "STEER_TASKS = list(STEER_CONFIG.get('tasks', []))\n",
    "\n",
    "# Client options\n",
    "client_settings = config_data.get('client', {}) or {}\n",
    "CLIENT_ASSISTANT_MODEL_URL = client_settings.get('assistant_model_url', 'https://api.openai.com/v1')\n",
    "CLIENT_ASSISTANT_MODEL_API_KEY = client_settings.get('assistant_model_api_key')\n",
    "CLIENT_ASSISTANT_MODEL_NAME = client_settings.get('assistant_model_name', 'gpt-4o-mini')\n",
    "CLIENT_STEER_API_KEY = client_settings.get('steer_api_key', 'demo-001')\n",
    "CLIENT_TIMEOUT = float(client_settings.get('timeout', 120))\n",
    "CLIENT_MAX_RETRIES = int(client_settings.get('max_retries', 3))\n",
    "CLIENT_RATE_LIMIT_RETRIES = int(client_settings.get('rate_limit_retries', 6))\n",
    "\n",
    "# Simulation options\n",
    "simulate_settings = config_data.get('simulate', {}) or {}\n",
    "SIM_SAMPLES = simulate_settings.get('k', 1)\n",
    "SIM_EXCHANGES = simulate_settings.get('num_exchanges', 2)\n",
    "SIM_DELAY = simulate_settings.get('batch_delay', 0.2)\n",
    "SIM_STEER_TEMPERATURE = simulate_settings.get('steer_temperature', 0.7)\n",
    "SIM_STEER_MAX_TOKENS = simulate_settings.get('steer_max_tokens', 256)\n",
    "SIM_MIX_TRAITS = bool(simulate_settings.get('mix_traits', False))\n",
    "SIM_MAX_CONCURRENCY = int(simulate_settings.get('max_concurrency', 8))\n",
    "\n",
    "# Assessment options\n",
    "assess_settings = config_data.get('assess', {}) or {}\n",
    "ASSESS_JUDGE_MODEL_URL = assess_settings.get('judge_model_url')\n",
    "ASSESS_JUDGE_MODEL_API_KEY = assess_settings.get('judge_model_api_key')\n",
    "ASSESS_JUDGE_MODEL_NAME = assess_settings.get('judge_model_name')\n",
    "ASSESS_TEMPERATURE = assess_settings.get('temperature', 0.0)\n",
    "ASSESS_MAX_TOKENS = assess_settings.get('max_tokens', 512)\n",
    "\n",
    "tasks_display = STEER_TASKS if STEER_TASKS else '<none>'\n",
    "print(f'Loaded simulation: {SIMULATION_CONFIG_FILE} | steering: {STEERING_CONFIG_FILE} | tasks: {tasks_display}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if CLIENT_ASSISTANT_MODEL_API_KEY:\n",
    "    os.environ['OPENAI_API_KEY'] = CLIENT_ASSISTANT_MODEL_API_KEY\n",
    "if CLIENT_ASSISTANT_MODEL_URL:\n",
    "    os.environ['OPENAI_BASE_URL'] = CLIENT_ASSISTANT_MODEL_URL\n",
    "if CLIENT_STEER_API_KEY:\n",
    "    os.environ['STEER_API_KEY'] = CLIENT_STEER_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36V2vEkc7WbE"
   },
   "source": [
    "## Client setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_SHN7Qq74o1"
   },
   "outputs": [],
   "source": [
    "# Client setup\n",
    "\n",
    "if not CLIENT_ASSISTANT_MODEL_API_KEY:\n",
    "    raise RuntimeError('assistant_model_api_key must be set in configs/simulation_config.json')\n",
    "\n",
    "client = Client(\n",
    "    assistant_model_url=CLIENT_ASSISTANT_MODEL_URL,\n",
    "    assistant_model_api_key=CLIENT_ASSISTANT_MODEL_API_KEY,\n",
    "    assistant_model_name=CLIENT_ASSISTANT_MODEL_NAME,\n",
    "    steer_api_key=CLIENT_STEER_API_KEY,\n",
    "    timeout=CLIENT_TIMEOUT,\n",
    "    max_retries=CLIENT_MAX_RETRIES,\n",
    "    rate_limit_retries=CLIENT_RATE_LIMIT_RETRIES,\n",
    ")\n",
    "\n",
    "runner = client.simulation_runner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKQEJx5_7pqi"
   },
   "source": [
    "## Simulate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16496,
     "status": "ok",
     "timestamp": 1757473448091,
     "user": {
      "displayName": "Quinten Lisowe",
      "userId": "05399425339750097468"
     },
     "user_tz": 300
    },
    "id": "R8AoPk5574Bb",
    "outputId": "521b92f7-95f1-4b25-cc31-ac1d26d2f314"
   },
   "outputs": [],
   "source": [
    "# Generate simulations\n",
    "\n",
    "simulations = client.simulate(\n",
    "    steer_config=STEER_CONFIG,\n",
    "    k=SIM_SAMPLES,\n",
    "    num_exchanges=SIM_EXCHANGES,\n",
    "    batch_delay=SIM_DELAY,\n",
    "    steer_temperature=SIM_STEER_TEMPERATURE,\n",
    "    steer_max_tokens=SIM_STEER_MAX_TOKENS,\n",
    "    mix_traits=SIM_MIX_TRAITS,\n",
    "    max_concurrency=SIM_MAX_CONCURRENCY,\n",
    ")\n",
    "\n",
    "\n",
    "# Save to file\n",
    "output_dir = Path()\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "dataset_path = output_dir / \"simulated_rl.jsonl\"\n",
    "with dataset_path.open('w', encoding='utf-8') as dataset_file:\n",
    "    for simulation in simulations:\n",
    "        dataset_row = make_dataset_row(runner, simulation)\n",
    "        dataset_file.write(json.dumps(dataset_row, ensure_ascii=False) + '\\n')\n",
    "print(f'Wrote dataset to: {dataset_path}')\n",
    "\n",
    "with open(\"simulated_rl.jsonl\") as f:\n",
    "    for i, x in enumerate(f):\n",
    "        print(\"=\"*8)\n",
    "        print(f\"Conversation {i+1}\")\n",
    "        print(\"=\"*8)\n",
    "        pprint(json.loads(x)[\"steering_persona\"])\n",
    "        print(json.loads(x)[\"conversation\"])\n",
    "        print(json.loads(x)[\"assistant_response\"])\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQfuz3uR7wg5"
   },
   "source": [
    "## Assess agent in multi-turn setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4463,
     "status": "ok",
     "timestamp": 1757473545636,
     "user": {
      "displayName": "Quinten Lisowe",
      "userId": "05399425339750097468"
     },
     "user_tz": 300
    },
    "id": "xGIbbY-U72pX",
    "outputId": "e09fb84d-60cd-432d-b12b-2bfbd77d9089"
   },
   "outputs": [],
   "source": [
    "# Assess\n",
    "result = client.assess(\n",
    "    dataset=simulations,\n",
    "    judge_model_url=ASSESS_JUDGE_MODEL_URL,\n",
    "    judge_model_api_key=ASSESS_JUDGE_MODEL_API_KEY,\n",
    "    judge_model_name=ASSESS_JUDGE_MODEL_NAME,\n",
    "    temperature=ASSESS_TEMPERATURE,\n",
    "    max_tokens=ASSESS_MAX_TOKENS,\n",
    ")\n",
    "print(f\"Assessment: {result.message or '<no message>'}\")\n",
    "\n",
    "with dataset_path.open('r', encoding='utf-8') as dataset_file:\n",
    "    dataset_rows = [json.loads(line) for line in dataset_file if line.strip()]\n",
    "\n",
    "for i, (scores_map, row) in enumerate(zip(result.evaluation_result, dataset_rows), start=1):\n",
    "    print('=' * 8)\n",
    "    print(f\"Conversation {i}\")\n",
    "    print('=' * 8)\n",
    "    pprint(row['steering_persona'])\n",
    "    print(row['conversation'])\n",
    "    print(row['assistant_response'])\n",
    "    for metric_name, scores in scores_map.items():\n",
    "        print(f\"  Score: {scores.score}\")\n",
    "        print(f\"  Rationale: {scores.rationale}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMI7Zd6-73Cx"
   },
   "source": [
    "## Make **realistic** RL environments for tool-use agents (Tau-Bench-**hard**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd tau-bench\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9X-eUX5KwpP"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tau_bench.types import RunConfig\n",
    "from tau_bench.run import run\n",
    "from litellm import provider_list\n",
    "from tau_bench.envs.user import UserStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tau_bench.types import RunConfig\n",
    "from tau_bench.run import run\n",
    "\n",
    "config = RunConfig(\n",
    "    model_provider=\"openai\",\n",
    "    user_model_provider=\"steer\",\n",
    "    model=CLIENT_ASSISTANT_MODEL_NAME,\n",
    "    user_model=\"\", # steer api abstracts the model\n",
    "    num_trials=1,\n",
    "    env=\"retail\",\n",
    "    agent_strategy=\"tool-calling\",\n",
    "    temperature=0.7,\n",
    "    task_split=\"test\",\n",
    "    start_index=0,\n",
    "    end_index=-1,\n",
    "    task_ids=[4],\n",
    "    log_dir=\"results\",\n",
    "    max_concurrency=1,\n",
    "    seed=10,\n",
    "    shuffle=0,\n",
    "    user_strategy=\"llm\",\n",
    "    few_shot_displays_path=None,\n",
    "    trait_dict={\"impatience\": 1, \"confusion\": 0, \"skeptical\": 0, \"incoherence\": 0},\n",
    ")\n",
    "\n",
    "print(\"FOR CLARITY, TOOL CALLS ARE NOT STREAMED BUT CAN BE VIEWED IN THE RESULTS FILE\")\n",
    "run(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "collinear-synthetic",
   "language": "python",
   "name": "collinear-synthetic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
